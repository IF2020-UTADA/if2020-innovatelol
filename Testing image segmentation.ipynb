{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"Testing image segmentation.ipynb","provenance":[],"collapsed_sections":[],"authorship_tag":"ABX9TyNjnXEIXqvsT/0vT6Vry+ds"},"kernelspec":{"name":"python3","display_name":"Python 3"}},"cells":[{"cell_type":"code","metadata":{"id":"ICbw-qTIp39a","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":140},"executionInfo":{"status":"ok","timestamp":1596816098813,"user_tz":240,"elapsed":5190,"user":{"displayName":"Kathy Zhuang","photoUrl":"","userId":"03973421984216267817"}},"outputId":"93f74cc4-ac74-444a-b2b4-ff6258a27e57"},"source":["pip install SmartCrop"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Collecting SmartCrop\n","  Downloading https://files.pythonhosted.org/packages/b2/d2/cd3edeb9012bce7a4b0ee95fe1c5254a891ddfdb71d74f63b021b61a8ed3/smartcrop-0.3.2-py3-none-any.whl\n","Requirement already satisfied: Pillow>=4.0.0 in /usr/local/lib/python3.6/dist-packages (from SmartCrop) (7.0.0)\n","Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from SmartCrop) (1.18.5)\n","Installing collected packages: SmartCrop\n","Successfully installed SmartCrop-0.3.2\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"LnapbJXhqExS","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":54},"executionInfo":{"status":"ok","timestamp":1596817354578,"user_tz":240,"elapsed":516,"user":{"displayName":"Kathy Zhuang","photoUrl":"","userId":"03973421984216267817"}},"outputId":"b6989b08-1b43-43e1-dc7d-54c4f70e7a53"},"source":["from google.colab import drive\n","drive.mount('/content/drive')\n","\n","master_path = '/content/drive/My Drive/APS360_Team17/CORe50/Testing cokes'\n"],"execution_count":3,"outputs":[{"output_type":"stream","text":["Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"TSLM_XQupbbp","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":241},"executionInfo":{"status":"ok","timestamp":1596817884320,"user_tz":240,"elapsed":12353,"user":{"displayName":"Kathy Zhuang","photoUrl":"","userId":"03973421984216267817"}},"outputId":"f5d703cf-9bc1-4d90-c3f6-06769a775551"},"source":["import json\n","import os\n","import sys\n","import cv2\n","\n","import smartcrop\n","from PIL import Image\n","import numpy as np\n","from matplotlib import pyplot as plt\n","# Load image\n","\n","def img_segment(file_dir,img_nobgr_dir,img_cropped):\n","    for img_file in os.listdir(img_dir):\n","        img = cv2.imread(os.path.join(img_dir, img_file), cv2.IMREAD_UNCHANGED)\n","        # Convert to RGB\n","        gray_img = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n","        _, thresh = cv2.threshold(gray_img, 230, 255, cv2.THRESH_BINARY_INV + cv2.THRESH_OTSU)\n","        img_contours = cv2.findContours(thresh, cv2.RETR_TREE, cv2.CHAIN_APPROX_SIMPLE)[-2]\n","\n","        img_contours = sorted(img_contours, key=cv2.contourArea)\n","\n","        for i in img_contours:\n","\n","            if cv2.contourArea(i) > 1000000000000:\n","                break\n","        mask = np.zeros(img.shape[:2], np.uint8)\n","        cv2.drawContours(mask, [i], -1, 255, -1)\n","        new_img = cv2.bitwise_and(img, img, mask=mask)\n","        img = cv2.resize(thresh, (500, 500))\n","        # cv2.imshow(\"Original Image\", img)\n","        # cv2.waitKey(0)\n","\n","        # show_img = cv2.resize(new_img, (500, 500))\n","\n","        # cv2.imshow(\"Image with background removed\", show_img)\n","        # cv2.waitKey(0)\n","        img_dir_new = img_nobgr_dir\n","        cv2.imwrite(os.path.join(img_dir_new,img_file),new_img)\n","        shape_detect_and_crop_3(img_dir_new,img_file,img_cropped)\n","\n","\n","def shape_detect_and_crop_3(img_dir_new,img_file,img_cropped):\n","    image = Image.open(os.path.join(img_dir_new,img_file))\n","    # image.show()\n","\n","    sc = smartcrop.SmartCrop()\n","    # ret = sc.crop(image, 100, 100)\n","    ret = sc.crop(image, 128, 128)\n","    box = (ret['top_crop']['x'],\n","           ret['top_crop']['y'],\n","           ret['top_crop']['width'] + ret['top_crop']['x'],\n","           ret['top_crop']['height'] + ret['top_crop']['y'])\n","    print(box)\n","    after_crop_img_dir =img_cropped\n","    img = image.crop(box)\n","    # img.show()\n","    save_img = img.resize((128,128))\n","    save_img.save(os.path.join(after_crop_img_dir,img_file))\n","\n","\n","        # print(json.dumps(result, indent=2))\n","\n","img_dir = master_path + '/original'\n","img_nobgr_dir =  master_path + '/no_bgr'\n","img_cropped =  master_path + '/cropped'\n","img_segment(img_dir,img_nobgr_dir,img_cropped)\n","    # shape_detect_and_crop_3(r'C:\\Users\\kathy\\PycharmProjects\\aps360\\ItemRecognitionSystem\\shape_detect')"],"execution_count":5,"outputs":[{"output_type":"stream","text":["(510, 0, 3227, 2717)\n","(510, 0, 3227, 2717)\n","(680, 0, 3397, 2717)\n","(510, 170, 3227, 2887)\n","(850, 0, 3567, 2717)\n","(1020, 170, 3737, 2887)\n","(1020, 0, 3737, 2717)\n","(510, 0, 3227, 2717)\n","(510, 0, 3227, 2717)\n","(680, 0, 3397, 2717)\n","(680, 0, 3397, 2717)\n","(680, 170, 3397, 2887)\n","(850, 0, 3567, 2717)\n"],"name":"stdout"}]}]}